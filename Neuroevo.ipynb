{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import gym\n",
    "import cv2\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from rq import Queue\n",
    "from redis import Redis\n",
    "\n",
    "import imageio\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "module_path = os.path.abspath(os.path.join('.'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from ga_model import *\n",
    "\n",
    "def to_np(x):\n",
    "    return x.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gym stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('SpaceInvadersDeterministic-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(6)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_img(im, figsize=None, ax=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    if len(im.shape) == 2:\n",
    "        ax.imshow(im, cmap='gray')\n",
    "    else:\n",
    "        ax.imshow(im)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    return ax\n",
    "\n",
    "def render(env, converted=False):\n",
    "    state = env.render(mode='rgb_array')\n",
    "    if converted:\n",
    "        state = convert_state(state)\n",
    "    plt.show(show_img(state))\n",
    "    \n",
    "reset(env)\n",
    "print(env.action_space)\n",
    "render(env)\n",
    "render(env, converted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We use the larger DQN architecture from Mnih et al. (2015) consisting of 3 convolutional layers with 32, 64, and 64 channels followed by a hidden layer\n",
    "with 512 units. The convolutional layers use 8 × 8, 4 × 4, and 3 × 3 filters with strides of 4, 2, and 1, respectively. All hidden layers were followed by a rectifier nonlinearity (ReLU). The network contains over 4M parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "for _ in range(4):\n",
    "    states.append(step(env, env.action_space.sample())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first try\n",
      "[[ 0.03239804  0.19395754 -0.2098617   0.03353743  0.09194227 -0.13298415\n",
      "  -0.11063922  0.31723318  0.05815194 -0.24815145  0.262236   -0.01782826\n",
      "  -0.12462022  0.21107364 -0.3389024   0.21397473 -0.03478914 -0.14867012]]\n",
      "didn't change anything, should be the same\n",
      "[[ 0.03239804  0.19395754 -0.2098617   0.03353743  0.09194227 -0.13298415\n",
      "  -0.11063922  0.31723318  0.05815194 -0.24815145  0.262236   -0.01782826\n",
      "  -0.12462022  0.21107364 -0.3389024   0.21397473 -0.03478914 -0.14867012]]\n",
      "after evolution, should be different but only slightly\n",
      "[[ 0.05251082  0.18131325 -0.15350634  0.04384021  0.12505715 -0.17079663\n",
      "  -0.07299246  0.29041347  0.02971918 -0.26136002  0.343796    0.00170177\n",
      "  -0.11745539  0.20116375 -0.3478058   0.17357613 -0.00394318 -0.11994842]]\n",
      "copied model, should be the same\n",
      "[[ 0.05251082  0.18131325 -0.15350634  0.04384021  0.12505715 -0.17079663\n",
      "  -0.07299246  0.29041347  0.02971918 -0.26136002  0.343796    0.00170177\n",
      "  -0.11745539  0.20116375 -0.3478058   0.17357613 -0.00394318 -0.11994842]]\n"
     ]
    }
   ],
   "source": [
    "m = Model(random_state())\n",
    "print('first try')\n",
    "print(to_np(m(Variable(torch.Tensor([states])))))\n",
    "print('didn\\'t change anything, should be the same')\n",
    "print(to_np(m(Variable(torch.Tensor([states])))))\n",
    "m.evolve(0.005, random_state())\n",
    "print('after evolution, should be different but only slightly')\n",
    "print(to_np(m(Variable(torch.Tensor([states])))))\n",
    "\n",
    "m2 = uncompress_model(m.compress())\n",
    "print('copied model, should be the same')\n",
    "print(to_np(m2(Variable(torch.Tensor([states])))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok great, it compiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDIS_HOST = '172.31.7.58'\n",
    "\n",
    "class FakeJob:\n",
    "    def __init__(self, j):\n",
    "        self.result = j.result\n",
    "\n",
    "class GA:\n",
    "    def __init__(self, population, compressed_models=None, queue_name='default'):\n",
    "        self.population = population\n",
    "        self.models = [CompressedModel() for _ in range(population)] if compressed_models is None else compressed_models\n",
    "        \n",
    "        self.redis = Redis(REDIS_HOST)\n",
    "        self.queue = Queue(connection=self.redis, name=queue_name)\n",
    "        for j in self.queue.jobs:\n",
    "            j.cancel()\n",
    "\n",
    "    # Note: the paper says \"20k frames\", but there are 4 frames per network\n",
    "    # evaluation, so we cap at 5k evaluations\n",
    "    def get_best_models(self, env, max_eval=5000, max_noop=30):\n",
    "        jobs = []\n",
    "        for m in self.models:\n",
    "            jobs.append(self.queue.enqueue(evaluate_model, env, m, max_eval=max_eval, max_noop=max_noop, ttl=650, timeout=600))\n",
    "        last_enqueue_time = time.time()\n",
    "        while True:\n",
    "            for i in range(len(jobs)):\n",
    "                if jobs[i].result is not None and not isinstance(jobs[i], FakeJob):\n",
    "                    if random.random() < 0.001:\n",
    "                        print(jobs[i].result)\n",
    "                    jobs[i] = FakeJob(jobs[i])\n",
    "                    \n",
    "            def convert_result(j):\n",
    "                if j.result is not None:\n",
    "                    if j.result[0] == 0.0 and j.result[1] == max_eval * 4 and 'Breakout' in env:\n",
    "                        return -1.0\n",
    "                    return j.result[0]\n",
    "                return None\n",
    "            scores = [convert_result(j) for j in jobs]\n",
    "            if None not in scores:\n",
    "                break\n",
    "            if time.time() - last_enqueue_time > 600:\n",
    "                print(f'Reenqueuing unfinished jobs ({sum(x is None for x in scores)}).')\n",
    "                for i in range(len(jobs)):\n",
    "                    if jobs[i].result is None:\n",
    "                        jobs[i].cancel()\n",
    "                        jobs[i] = self.queue.enqueue(\n",
    "                            evaluate_model, env, self.models[i], max_eval=max_eval, max_noop=max_noop, ttl=650, timeout=600)\n",
    "                last_enqueue_time = time.time()\n",
    "            time.sleep(1)\n",
    "        used_frames = sum(j.result[1] for j in jobs)\n",
    "        scored_models = list(zip(self.models, scores))\n",
    "        scored_models.sort(key=lambda x: x[1], reverse=True)\n",
    "        return scored_models, used_frames\n",
    "\n",
    "    def evolve_iter(self, env, sigma=0.005, truncation=10, max_eval=5000, max_noop=30):\n",
    "        scored_models, used_frames = self.get_best_models(env, max_eval=max_eval, max_noop=max_noop)\n",
    "        scores = [s for _, s in scored_models]\n",
    "        median_score = np.median(scores)\n",
    "        mean_score = np.mean(scores)\n",
    "        max_score = scored_models[0][1]\n",
    "        scored_models = scored_models[:truncation]\n",
    "        \n",
    "        # Elitism\n",
    "        self.models = [scored_models[0][0]]\n",
    "        for _ in range(self.population):\n",
    "            self.models.append(copy.deepcopy(random.choice(scored_models)[0]))\n",
    "            self.models[-1].evolve(sigma)\n",
    "            \n",
    "        return median_score, mean_score, max_score, used_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = GA(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20.0, 1468)\n",
      "(105.0, 2184)\n",
      "(400.0, 3612)\n",
      "(140.0, 3140)\n",
      "(0.0, 2504)\n",
      "(190.0, 2412)\n",
      "(0.0, 3660)\n",
      "(245.0, 3940)\n",
      "Done with generation!\n",
      "Median: 120.0, average: 144.739, max: 880.0, frames: 15,131,976\n",
      "(50.0, 1396)\n",
      "(280.0, 3044)\n",
      "(200.0, 4460)\n",
      "(595.0, 5516)\n",
      "Done with generation!\n",
      "Median: 210.0, average: 234.50309938012398, max: 1000.0, frames: 32,375,992\n",
      "(260.0, 3916)\n",
      "(275.0, 3964)\n",
      "Done with generation!\n",
      "Median: 210.0, average: 262.46350729854026, max: 1210.0, frames: 50,348,844\n",
      "(410.0, 3132)\n",
      "(440.0, 3824)\n",
      "(140.0, 2620)\n",
      "(440.0, 3948)\n",
      "(230.0, 3520)\n",
      "(155.0, 3024)\n",
      "(210.0, 2720)\n",
      "(270.0, 3660)\n",
      "Done with generation!\n",
      "Median: 240.0, average: 311.81363727254546, max: 1240.0, frames: 69,855,788\n",
      "(105.0, 2128)\n",
      "Done with generation!\n",
      "Median: 240.0, average: 310.2009598080384, max: 1345.0, frames: 89,330,796\n",
      "(490.0, 4272)\n",
      "(105.0, 2504)\n",
      "(210.0, 3184)\n",
      "(460.0, 3840)\n",
      "Done with generation!\n",
      "Median: 260.0, average: 338.1523695260948, max: 1345.0, frames: 109,691,816\n",
      "(555.0, 5388)\n",
      "(375.0, 5532)\n",
      "(180.0, 3160)\n",
      "Done with generation!\n",
      "Median: 255.0, average: 326.44271145770847, max: 1345.0, frames: 129,713,052\n",
      "(740.0, 5512)\n",
      "(250.0, 3676)\n",
      "(360.0, 4128)\n",
      "(520.0, 4320)\n",
      "Done with generation!\n",
      "Median: 245.0, average: 322.53149370125976, max: 1345.0, frames: 149,548,688\n",
      "(180.0, 3276)\n",
      "(405.0, 5336)\n",
      "(285.0, 3884)\n",
      "(210.0, 3248)\n",
      "(290.0, 4416)\n",
      "(105.0, 2396)\n",
      "Done with generation!\n",
      "Median: 260.0, average: 347.5094981003799, max: 1415.0, frames: 170,517,820\n",
      "(260.0, 3784)\n",
      "(335.0, 4472)\n",
      "(410.0, 5844)\n",
      "(300.0, 4428)\n",
      "(720.0, 7624)\n",
      "(810.0, 6976)\n",
      "Done with generation!\n",
      "Median: 290.0, average: 371.3467306538692, max: 1415.0, frames: 192,093,380\n",
      "(300.0, 4256)\n",
      "(765.0, 5828)\n",
      "(1210.0, 10920)\n",
      "(465.0, 3988)\n",
      "(355.0, 5648)\n",
      "(545.0, 5860)\n",
      "Done with generation!\n",
      "Median: 315.0, average: 388.0803839232154, max: 1415.0, frames: 214,267,108\n",
      "(260.0, 3812)\n",
      "(465.0, 4016)\n",
      "(210.0, 3304)\n",
      "(210.0, 3344)\n",
      "(550.0, 5652)\n",
      "Done with generation!\n",
      "Median: 285.0, average: 374.1491701659668, max: 1415.0, frames: 235,897,984\n",
      "(880.0, 7040)\n",
      "(655.0, 6272)\n",
      "(895.0, 6400)\n",
      "(180.0, 3176)\n",
      "(460.0, 3912)\n",
      "(180.0, 3244)\n",
      "(265.0, 3820)\n",
      "(210.0, 3420)\n",
      "Done with generation!\n",
      "Median: 270.0, average: 369.4601079784043, max: 1415.0, frames: 257,332,608\n",
      "(180.0, 3232)\n",
      "(155.0, 3160)\n",
      "(180.0, 3192)\n",
      "Done with generation!\n",
      "Median: 340.0, average: 402.3475304939012, max: 1535.0, frames: 279,563,756\n",
      "(330.0, 4844)\n",
      "(410.0, 3480)\n",
      "(765.0, 5784)\n",
      "(260.0, 3348)\n",
      "(300.0, 4252)\n",
      "(290.0, 4340)\n",
      "(600.0, 4380)\n",
      "(105.0, 2508)\n",
      "Done with generation!\n",
      "Median: 365.0, average: 413.04239152169566, max: 1545.0, frames: 301,950,632\n",
      "(470.0, 3996)\n",
      "(210.0, 3288)\n",
      "(765.0, 5808)\n",
      "(350.0, 5720)\n",
      "(440.0, 3868)\n",
      "(985.0, 7356)\n",
      "(180.0, 3188)\n",
      "Done with generation!\n",
      "Median: 470.0, average: 476.5646870625875, max: 1640.0, frames: 325,852,680\n",
      "(725.0, 6356)\n",
      "(105.0, 2580)\n",
      "(835.0, 5940)\n",
      "(470.0, 3816)\n",
      "(180.0, 3264)\n",
      "(135.0, 3144)\n",
      "Done with generation!\n",
      "Median: 485.0, average: 476.9426114777045, max: 1930.0, frames: 349,671,348\n",
      "(500.0, 4160)\n",
      "(180.0, 3168)\n",
      "(460.0, 4224)\n",
      "(505.0, 4016)\n",
      "(180.0, 3268)\n",
      "(210.0, 3344)\n",
      "Done with generation!\n",
      "Median: 465.0, average: 458.74625074985005, max: 1930.0, frames: 372,636,084\n",
      "(535.0, 5696)\n",
      "(180.0, 3264)\n",
      "(180.0, 3204)\n",
      "Done with generation!\n",
      "Median: 440.0, average: 430.19496100779844, max: 1930.0, frames: 395,265,816\n",
      "(590.0, 5796)\n",
      "(180.0, 3436)\n",
      "(180.0, 3228)\n",
      "(565.0, 5852)\n",
      "(495.0, 4024)\n",
      "(440.0, 3976)\n",
      "Done with generation!\n",
      "Median: 470.0, average: 461.0147970405919, max: 1930.0, frames: 418,618,852\n",
      "(180.0, 3240)\n",
      "(285.0, 3808)\n",
      "(590.0, 5808)\n",
      "(440.0, 3488)\n",
      "(180.0, 3164)\n",
      "Done with generation!\n",
      "Median: 440.0, average: 444.3921215756849, max: 1930.0, frames: 441,387,164\n",
      "(180.0, 3180)\n",
      "(210.0, 3172)\n",
      "(495.0, 4048)\n",
      "(315.0, 4596)\n",
      "(180.0, 3508)\n",
      "Done with generation!\n",
      "Median: 470.0, average: 463.0253949210158, max: 1930.0, frames: 464,615,612\n",
      "(580.0, 5740)\n",
      "(745.0, 5432)\n",
      "(180.0, 3216)\n",
      "Done with generation!\n",
      "Median: 460.0, average: 462.5514897020596, max: 1930.0, frames: 487,942,196\n",
      "(695.0, 6296)\n",
      "(180.0, 3172)\n",
      "(135.0, 2608)\n",
      "(590.0, 6548)\n",
      "(690.0, 6440)\n",
      "Done with generation!\n",
      "Median: 470.0, average: 492.9004199160168, max: 1930.0, frames: 512,255,872\n",
      "(275.0, 3996)\n",
      "(930.0, 7040)\n",
      "(355.0, 3244)\n",
      "(460.0, 4216)\n",
      "(860.0, 9780)\n",
      "(180.0, 3188)\n",
      "Done with generation!\n",
      "Median: 440.0, average: 456.28474305138974, max: 1930.0, frames: 535,351,584\n",
      "(180.0, 3260)\n",
      "Done with generation!\n",
      "Median: 495.0, average: 506.4917016596681, max: 1930.0, frames: 560,002,688\n",
      "(180.0, 3188)\n",
      "(260.0, 3980)\n",
      "(440.0, 3836)\n",
      "(650.0, 6220)\n",
      "(1240.0, 9476)\n",
      "(650.0, 6788)\n",
      "(180.0, 3252)\n",
      "(180.0, 3264)\n",
      "(265.0, 3848)\n",
      "(180.0, 3176)\n",
      "(540.0, 5820)\n",
      "Done with generation!\n",
      "Median: 455.0, average: 464.0781843631274, max: 1930.0, frames: 583,681,932\n",
      "(925.0, 7232)\n",
      "(105.0, 2520)\n",
      "(580.0, 5696)\n",
      "(440.0, 3936)\n",
      "(570.0, 5892)\n",
      "Done with generation!\n",
      "Median: 520.0, average: 509.8560287942411, max: 1930.0, frames: 608,593,956\n",
      "(410.0, 4884)\n",
      "(395.0, 5288)\n",
      "(870.0, 6224)\n",
      "Done with generation!\n",
      "Median: 460.0, average: 468.4423115376925, max: 1930.0, frames: 632,492,164\n",
      "(495.0, 4284)\n",
      "(505.0, 4240)\n",
      "(135.0, 2676)\n",
      "(290.0, 4304)\n",
      "Done with generation!\n",
      "Median: 440.0, average: 433.35632873425317, max: 1930.0, frames: 655,559,744\n",
      "(180.0, 3220)\n",
      "(180.0, 3220)\n",
      "(180.0, 3188)\n",
      "(180.0, 3048)\n",
      "(580.0, 5692)\n",
      "(550.0, 5808)\n",
      "(240.0, 3904)\n",
      "(420.0, 5976)\n",
      "Done with generation!\n",
      "Median: 315.0, average: 406.69466106778646, max: 1930.0, frames: 677,765,996\n",
      "(440.0, 3824)\n",
      "(620.0, 5740)\n",
      "(310.0, 4012)\n",
      "(375.0, 5620)\n",
      "(180.0, 3260)\n",
      "Done with generation!\n",
      "Median: 440.0, average: 459.93001399720055, max: 1930.0, frames: 701,396,272\n",
      "(440.0, 3732)\n",
      "(455.0, 4948)\n",
      "(635.0, 7712)\n",
      "(440.0, 3836)\n",
      "(210.0, 2996)\n",
      "Done with generation!\n",
      "Median: 420.0, average: 453.40731853629273, max: 1930.0, frames: 724,743,452\n",
      "(550.0, 5600)\n",
      "(180.0, 3480)\n",
      "(545.0, 5648)\n",
      "(180.0, 3252)\n",
      "(180.0, 3260)\n",
      "(180.0, 3096)\n",
      "Done with generation!\n",
      "Median: 470.0, average: 484.52209558088384, max: 1930.0, frames: 749,032,580\n",
      "(270.0, 3944)\n",
      "(695.0, 6232)\n",
      "(180.0, 3248)\n",
      "(580.0, 5764)\n",
      "Done with generation!\n",
      "Median: 485.0, average: 506.10277944411115, max: 1930.0, frames: 773,932,284\n",
      "(315.0, 5648)\n",
      "(510.0, 4268)\n",
      "Done with generation!\n",
      "Median: 510.0, average: 530.0229954009199, max: 1930.0, frames: 799,349,260\n",
      "(620.0, 5808)\n",
      "Done with generation!\n",
      "Median: 495.0, average: 512.6894621075785, max: 1930.0, frames: 824,100,044\n",
      "(515.0, 3664)\n",
      "(790.0, 5992)\n",
      "(580.0, 5676)\n",
      "(590.0, 5812)\n",
      "(1005.0, 6076)\n",
      "(105.0, 2624)\n",
      "(520.0, 4260)\n",
      "Done with generation!\n",
      "Median: 475.0, average: 488.1753649270146, max: 1930.0, frames: 848,024,884\n",
      "(180.0, 3184)\n",
      "(260.0, 3848)\n",
      "(180.0, 3068)\n",
      "(180.0, 3252)\n",
      "Done with generation!\n",
      "Median: 520.0, average: 543.5482903419316, max: 1930.0, frames: 873,297,476\n",
      "(725.0, 7208)\n",
      "(505.0, 4348)\n",
      "(1135.0, 8508)\n",
      "(265.0, 3892)\n",
      "(580.0, 5724)\n",
      "(565.0, 6572)\n",
      "Done with generation!\n",
      "Median: 565.0, average: 562.8244351129774, max: 1930.0, frames: 899,452,860\n",
      "(885.0, 6480)\n",
      "(320.0, 4404)\n",
      "(230.0, 3428)\n",
      "(520.0, 4360)\n",
      "Done with generation!\n",
      "Median: 490.0, average: 506.4757048590282, max: 1930.0, frames: 924,110,428\n",
      "(1130.0, 7544)\n",
      "(460.0, 3856)\n",
      "(1440.0, 10348)\n",
      "(180.0, 3124)\n",
      "(180.0, 3256)\n",
      "(580.0, 5760)\n",
      "(580.0, 5712)\n",
      "Done with generation!\n",
      "Median: 565.0, average: 565.5118976204759, max: 1930.0, frames: 950,304,680\n",
      "(210.0, 2572)\n",
      "(180.0, 3252)\n",
      "(665.0, 6388)\n",
      "(545.0, 4308)\n",
      "Done with generation!\n",
      "Median: 545.0, average: 559.5400919816037, max: 1930.0, frames: 976,146,684\n",
      "(180.0, 3156)\n",
      "(460.0, 3712)\n",
      "(580.0, 5776)\n",
      "(980.0, 7324)\n",
      "(500.0, 4424)\n",
      "(470.0, 3956)\n",
      "(180.0, 3204)\n",
      "(580.0, 5740)\n",
      "Done with generation!\n",
      "Median: 525.0, average: 549.3171365726855, max: 2030.0, frames: 1,001,771,988\n"
     ]
    }
   ],
   "source": [
    "total_frames = 0\n",
    "while total_frames < 1_000_000_000:\n",
    "    if 'Breakout' in env.spec.id and total_frames < 10_000_000:\n",
    "        med, avg, M, frames = ga.evolve_iter(env.spec.id, max_eval=400)\n",
    "    else:\n",
    "        med, avg, M, frames = ga.evolve_iter(env.spec.id)\n",
    "    total_frames += frames\n",
    "    print(f'Done with generation!\\nMedian: {med}, average: {avg}, max: {M}, frames: {total_frames:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180.0, 3224)\n",
      "(110.0, 2632)\n",
      "(460.0, 3812)\n",
      "(805.0, 6080)\n",
      "(180.0, 3272)\n"
     ]
    }
   ],
   "source": [
    "best_models = ga.get_best_models(env.spec.id)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_models, open(f'{env.spec.id}_best.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = pickle.load(open(f'{env.spec.id}_best.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_video(env, model, max_eval=200000, max_noop=30):\n",
    "    env = gym.make(env)\n",
    "    model = uncompress_model(model)\n",
    "    noops = random.randint(0, max_noop)\n",
    "    cur_states = [reset(env)] * 4\n",
    "    total_reward = 0\n",
    "    frames = [env.render(mode='rgb_array')]\n",
    "    for _ in range(noops):\n",
    "        cur_states.pop(0)\n",
    "        new_state, reward, is_done, _ = step(env, 0)\n",
    "        frames.append(env.render(mode='rgb_array'))\n",
    "        total_reward += reward\n",
    "        if is_done:\n",
    "            return total_reward\n",
    "        cur_states.append(new_state)\n",
    "\n",
    "    model.eval()\n",
    "    for _ in range(max_eval):\n",
    "        values = model(Variable(torch.Tensor([cur_states])))[0]\n",
    "        action = np.argmax(values.data.numpy()[:env.action_space.n])\n",
    "        new_state, reward, is_done, _ = step(env, action)\n",
    "        frames.append(env.render(mode='rgb_array'))\n",
    "        total_reward += reward\n",
    "        if is_done:\n",
    "            break\n",
    "        cur_states.pop(0)\n",
    "        cur_states.append(new_state)\n",
    "\n",
    "    return total_reward, frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, video = make_video(env.spec.id, best_models[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2030.0\n"
     ]
    }
   ],
   "source": [
    "print(score)\n",
    "imageio.mimsave(f'{env.spec.id}.gif', video + [video[-1]] * 10, fps=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
