{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import gym\n",
    "import cv2\n",
    "import copy\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import threading\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from rq import Queue\n",
    "from redis import Redis\n",
    "\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "module_path = os.path.abspath(os.path.join('.'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from ga_model import *\n",
    "\n",
    "def to_np(x):\n",
    "    return x.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gym stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-03-21 00:20:40,332] Making new env: FrostbiteDeterministic-v4\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrostbiteDeterministic-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(18)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_img(im, figsize=None, ax=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    if len(im.shape) == 2:\n",
    "        ax.imshow(im, cmap='gray')\n",
    "    else:\n",
    "        ax.imshow(im)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    return ax\n",
    "\n",
    "def render(env, converted=False):\n",
    "    state = env.render(mode='rgb_array')\n",
    "    if converted:\n",
    "        state = convert_state(state)\n",
    "    plt.show(show_img(state))\n",
    "    \n",
    "reset(env)\n",
    "print(env.action_space)\n",
    "render(env)\n",
    "render(env, converted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We use the larger DQN architecture from Mnih et al. (2015) consisting of 3 convolutional layers with 32, 64, and 64 channels followed by a hidden layer\n",
    "with 512 units. The convolutional layers use 8 × 8, 4 × 4, and 3 × 3 filters with strides of 4, 2, and 1, respectively. All hidden layers were followed by a rectifier nonlinearity (ReLU). The network contains over 4M parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "for _ in range(4):\n",
    "    states.append(step(env, env.action_space.sample())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first try\n",
      "[[ 0.1191228  -0.8711898   0.42776275  0.19066775  0.16241857  0.8035878\n",
      "  -0.61707604 -1.0426903   0.3129349   0.30215982  1.2460183  -0.80302775\n",
      "  -0.6828691  -0.2374751  -0.2536229  -0.5345104  -0.8301259  -1.2509856 ]]\n",
      "didn't change anything, should be the same\n",
      "[[ 0.1191228  -0.8711898   0.42776275  0.19066775  0.16241857  0.8035878\n",
      "  -0.61707604 -1.0426903   0.3129349   0.30215982  1.2460183  -0.80302775\n",
      "  -0.6828691  -0.2374751  -0.2536229  -0.5345104  -0.8301259  -1.2509856 ]]\n",
      "after evolution, should be different but only slightly\n",
      "[[ 0.23844606 -0.90780354  0.6174349   0.20491223  0.18856826  1.0275394\n",
      "  -0.6806948  -1.3485574   0.20656978  0.44525886  1.4826114  -1.0349385\n",
      "  -0.75016254 -0.45254272 -0.12576383 -0.5637666  -0.7704897  -1.347951  ]]\n",
      "copied model, should be the same\n",
      "[[ 0.1191228  -0.8711898   0.42776275  0.19066775  0.16241857  0.8035878\n",
      "  -0.61707604 -1.0426903   0.3129349   0.30215982  1.2460183  -0.80302775\n",
      "  -0.6828691  -0.2374751  -0.2536229  -0.5345104  -0.8301259  -1.2509856 ]]\n"
     ]
    }
   ],
   "source": [
    "m = Model(random_state())\n",
    "print('first try')\n",
    "print(to_np(m(Variable(torch.Tensor([states])))))\n",
    "print('didn\\'t change anything, should be the same')\n",
    "print(to_np(m(Variable(torch.Tensor([states])))))\n",
    "m.evolve(0.005, random_state())\n",
    "print('after evolution, should be different but only slightly')\n",
    "print(to_np(m(Variable(torch.Tensor([states])))))\n",
    "\n",
    "m2 = uncompress_model(m.compress())\n",
    "print('copied model, should be the same')\n",
    "print(to_np(m2(Variable(torch.Tensor([states])))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok great, it compiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GA:\n",
    "    def __init__(self, population, compressed_models=None, queue_name='default'):\n",
    "        self.population = population\n",
    "        self.models = [CompressedModel() for _ in range(population)] if compressed_models is None else compressed_models\n",
    "        \n",
    "        self.redis = Redis()\n",
    "        self.queue = Queue(connection=self.redis, name=queue_name)\n",
    "        for j in self.queue.jobs:\n",
    "            j.cancel()\n",
    "\n",
    "    def get_best_models(self, env, max_eval=20000, max_noop=30):\n",
    "        jobs = []\n",
    "        for m in self.models:\n",
    "            jobs.append(self.queue.enqueue(evaluate_model, env, m, max_eval=max_eval, max_noop=max_noop, result_ttl=86400))\n",
    "        last_enqueue_time = time.time()\n",
    "        while True:\n",
    "            scores = [j.result for j in jobs]\n",
    "            if None not in scores:\n",
    "                break\n",
    "            if time.time() - last_enqueue_time > 60:\n",
    "                print(f'Reenqueuing unfinished jobs ({sum(x is None for x in scores)}).')\n",
    "                for i in range(len(jobs)):\n",
    "                    if jobs[i].result is None:\n",
    "                        jobs[i].cancel()\n",
    "                        jobs[i] = self.queue.enqueue(\n",
    "                            evaluate_model, env, self.models[i], max_eval=max_eval, max_noop=max_noop, result_ttl=86400)\n",
    "                last_enqueue_time = time.time()\n",
    "            time.sleep(1)\n",
    "        scored_models = list(zip(self.models, scores))\n",
    "        scored_models.sort(key=lambda x: x[1], reverse=True)\n",
    "        return scored_models\n",
    "\n",
    "    def evolve_iter(self, env, sigma=0.005, truncation=10, max_eval=20000, max_noop=30):\n",
    "        scored_models = self.get_best_models(env, max_eval=max_eval, max_noop=max_noop)\n",
    "        scores = [s for _, s in scored_models]\n",
    "        median_score = np.median(scores)\n",
    "        mean_score = np.mean(scores)\n",
    "        max_score = scored_models[0][1]\n",
    "        scored_models = scored_models[:truncation]\n",
    "        \n",
    "        # Elitism\n",
    "        self.models = [scored_models[0][0]]\n",
    "        for _ in range(self.population):\n",
    "            self.models.append(copy.deepcopy(random.choice(scored_models)[0]))\n",
    "            self.models[-1].evolve(sigma)\n",
    "            \n",
    "        return median_score, mean_score, max_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = GA(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reenqueuing unfinished jobs (93).\n",
      "Reenqueuing unfinished jobs (85).\n",
      "Reenqueuing unfinished jobs (76).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-60299a27f078>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mga\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevolve_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-ea31eaeb77a9>\u001b[0m in \u001b[0;36mevolve_iter\u001b[0;34m(self, env, sigma, truncation, max_eval, max_noop)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevolve_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_noop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mscored_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_noop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_noop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscored_models\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mmedian_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-ea31eaeb77a9>\u001b[0m in \u001b[0;36mget_best_models\u001b[0;34m(self, env, max_eval, max_noop)\u001b[0m\n\u001b[1;32m     26\u001b[0m                             evaluate_model, env, self.models[i], max_eval=max_eval, max_noop=max_noop, result_ttl=86400)\n\u001b[1;32m     27\u001b[0m                 \u001b[0mlast_enqueue_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mscored_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mscored_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(ga.evolve_iter(env.spec.id, max_eval=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
